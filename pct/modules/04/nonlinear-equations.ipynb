{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear Equations\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Nonlinear equations are ubiquitous in scientific computing. In power systems,\n",
    "the AC power flow equations are nonlinear equations.\n",
    "\n",
    "The standard form of nonlinear equations is:\n",
    "\n",
    "$$\n",
    "f(x) = 0\n",
    "$$\n",
    "\n",
    "where `f` is a nonlinear function and `x` is the variable. In other\n",
    "words, solving nonlinear equations means finding the roots of a function. This\n",
    "function is called the **residual** function, which will be small enough (zero\n",
    "at the tolerance level) when the solution is found. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Function\n",
    "\n",
    "The way to represent a nonlinear equation is to define the residual function.\n",
    "This is straightforward for simple problems in Python.\n",
    "\n",
    "Consider this problem from `scipy.optimize.fsolve` documentation:\n",
    "\n",
    "$$\n",
    "x_0 \\cos(x_1) = 4\n",
    "$$\n",
    "\n",
    "$$\n",
    "x_1 x_0 - x_1 = 5\n",
    "$$\n",
    "\n",
    "we can define the residual function as:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def residual(x):\n",
    "    return [x[0]*np.cos(x[1]) - 4,\n",
    "            x[0]*x[1] - x[1] - 5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for the function argument `x`, it is implicitly a 1D NumPy array. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root-Finding with `fsolve`\n",
    "\n",
    "One of the most common methods to solve nonlinear equations is the\n",
    "[Newton-Raphson method](https://en.wikipedia.org/wiki/Newton%27s_method). In\n",
    "practice, for simple problems, we can use off-the-shelf solvers in Python.\n",
    "\n",
    "`fsolve` is a function in `scipy.optimize` for root-finding. We can check the\n",
    "docstring by typing `?fsolve` in a Jupyter cell or visiting the [documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fsolve.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.50409711 0.90841421]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import fsolve\n",
    "\n",
    "x0 = [1, 1]\n",
    "sol = fsolve(residual, x0)\n",
    "print(sol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(residual(sol), [0.0, 0.0])  # the residual at the solution should be almost 0.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacobian Matrix\n",
    "\n",
    "SciPy's `fsolve` uses the [Powell's hybrid\n",
    "method](https://en.wikipedia.org/wiki/Powell%27s_dog_leg_method), which combines\n",
    "the Newton-Raphson method with gradient descent. They require the Jacobian\n",
    "matrix, which is the first-order derivatives of the residual function w.r.t the\n",
    "unknown variables.\n",
    "\n",
    "Calculating the Jacobian matrix is computationally expensive. By default,\n",
    "`fsolve` uses the `hybrd` method in MINPACK, which calculates the Jacobian\n",
    "matrix using finite differences. For each column of the Jacobian matrix, two\n",
    "evaluations of the residual functions are needed, resulting in a total of `2N`\n",
    "residual evaluations for an N-dimensional problem.\n",
    "\n",
    "Providing the Jacobian matrix can speed up the calculation. This is one of the\n",
    "reasons why texts on power system analysis always show Jacobian matrix. \n",
    "\n",
    "`fsolve` allows specifying the function that provides the Jacobian matrix\n",
    "through the `fprime` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clarify, the Jacobian function is the first-order derivatives of the\n",
    "**residual function** w.r.t the unknown variables. It is not necessarily the\n",
    "derivative of the **original function** w.r.t the unknown variables.\n",
    "\n",
    "In this case, the residual function is:\n",
    "\n",
    "$$\n",
    "r_0 = \n",
    "\\begin{bmatrix}\n",
    "x_0 \\cos(x_1) - 4 \\\\\n",
    "x_0 x_1 - x_1 - 5\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "And the unkonwns are\n",
    "\n",
    "$$\n",
    "x = \\begin{bmatrix}\n",
    "x_0 \\\\\n",
    "x_1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Therefore, the **analytical** Jacobian matrix is:\n",
    "\n",
    "$$\n",
    "J = \\begin{bmatrix}\n",
    "\\frac{\\partial r_0}{\\partial x_0} & \\frac{\\partial r_0}{\\partial x_1} \\\\\n",
    "\\frac{\\partial r_1}{\\partial x_0} & \\frac{\\partial r_1}{\\partial x_1}\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "\\cos(x_1) & -x_0 \\sin(x_1) \\\\\n",
    "x_1 & x_0 - 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "It is called the analytical Jacobian matrix because it is derived based on\n",
    "calculus. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.50409711 0.90841421]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def jacobian(x):\n",
    "    return [[np.cos(x[1]), -x[0]*np.sin(x[1])],\n",
    "            [x[1], x[0] - 1]]\n",
    "\n",
    "\n",
    "sol = fsolve(residual, x0, fprime=jacobian)\n",
    "print(sol)\n",
    "\n",
    "np.isclose(residual(sol), [0.0, 0.0])  # the residual at the solution should be almost 0.0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this small example, we cannot see the performance gain from providing the\n",
    "Jacobian matrix. However, this will be illustrated by a power flow problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Flow Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Custom Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

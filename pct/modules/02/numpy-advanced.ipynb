{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced NumPy\n",
    "\n",
    "```{admonition} Information\n",
    ":class: info\n",
    "\n",
    "**Prerequisites:** Module 02 Lessons 1-2 (Python Fundamentals, NumPy Basics)  \n",
    "**Learning Objectives:**\n",
    "- Work with sparse matrices for large power system problems\n",
    "- Apply advanced linear algebra techniques\n",
    "- Optimize NumPy code for performance\n",
    "- Prepare for numerical methods in Module 04\n",
    "- Handle large-scale power system data efficiently\n",
    "\n",
    "**Estimated Time:** 2 hours\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Power system analysis often involves large networks with thousands of buses and branches. These systems result in sparse matrices where most elements are zero. This lesson introduces advanced NumPy techniques and sparse matrix operations essential for efficient power system computation. These skills directly prepare you for the numerical methods covered in Module 04.\n",
    "\n",
    "We'll explore how to leverage sparsity, perform efficient linear algebra operations, and optimize code for large-scale problems while maintaining the clarity and correctness required for engineering applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import linalg as sp_linalg\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Sparse Matrices\n",
    "\n",
    "In power systems, network matrices are naturally sparse because each bus is only connected to a few neighboring buses. Understanding and exploiting this sparsity is crucial for computational efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Sparse Matrices Matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare memory usage: dense vs sparse\n",
    "# Simulate a power system network matrix\n",
    "n_buses = 1000\n",
    "avg_connections = 3  # Average connections per bus\n",
    "\n",
    "# Create a sparse connection pattern\n",
    "# Each bus connects to avg_connections other buses\n",
    "connections = []\n",
    "for i in range(n_buses):\n",
    "    # Connect to nearby buses\n",
    "    for j in range(1, avg_connections + 1):\n",
    "        if i + j < n_buses:\n",
    "            connections.append((i, i + j))\n",
    "            connections.append((i + j, i))  # Symmetric\n",
    "\n",
    "# Remove duplicates\n",
    "connections = list(set(connections))\n",
    "n_connections = len(connections)\n",
    "\n",
    "print(f\"Network Statistics:\")\n",
    "print(f\"Number of buses: {n_buses}\")\n",
    "print(f\"Number of connections: {n_connections}\")\n",
    "print(f\"Sparsity: {n_connections / (n_buses * n_buses) * 100:.2f}%\")\n",
    "\n",
    "# Create dense matrix\n",
    "dense_matrix = np.zeros((n_buses, n_buses))\n",
    "for i, j in connections:\n",
    "    dense_matrix[i, j] = np.random.uniform(0.01, 0.1)\n",
    "\n",
    "# Create sparse matrix\n",
    "row_ind = [c[0] for c in connections]\n",
    "col_ind = [c[1] for c in connections]\n",
    "data = np.random.uniform(0.01, 0.1, n_connections)\n",
    "sparse_matrix = sp.csr_matrix((data, (row_ind, col_ind)), \n",
    "                             shape=(n_buses, n_buses))\n",
    "\n",
    "# Compare memory usage\n",
    "dense_memory = dense_matrix.nbytes / 1024 / 1024  # MB\n",
    "sparse_memory = (sparse_matrix.data.nbytes + \n",
    "                sparse_matrix.indices.nbytes + \n",
    "                sparse_matrix.indptr.nbytes) / 1024 / 1024  # MB\n",
    "\n",
    "print(f\"\\nMemory Usage:\")\n",
    "print(f\"Dense matrix: {dense_memory:.2f} MB\")\n",
    "print(f\"Sparse matrix: {sparse_memory:.2f} MB\")\n",
    "print(f\"Memory savings: {(1 - sparse_memory/dense_memory)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Matrix Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different sparse matrix formats for different purposes\n",
    "# Small example for visualization\n",
    "n = 5\n",
    "# Y-bus like structure: diagonal dominant with few off-diagonal elements\n",
    "row = [0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4]\n",
    "col = [0, 1, 0, 1, 2, 1, 2, 3, 2, 3, 4, 3, 4]\n",
    "data = [3, -1, -1, 4, -2, -2, 5, -1, -1, 4, -2, -2, 3]\n",
    "\n",
    "# Create different formats\n",
    "coo = sp.coo_matrix((data, (row, col)), shape=(n, n))\n",
    "csr = coo.tocsr()  # Compressed Sparse Row\n",
    "csc = coo.tocsc()  # Compressed Sparse Column\n",
    "dok = coo.todok()  # Dictionary of Keys\n",
    "lil = coo.tolil()  # List of Lists\n",
    "\n",
    "print(\"Sparse Matrix Formats:\")\n",
    "print(\"\\n1. COO (Coordinate) Format:\")\n",
    "print(f\"   Data: {coo.data}\")\n",
    "print(f\"   Row indices: {coo.row}\")\n",
    "print(f\"   Col indices: {coo.col}\")\n",
    "\n",
    "print(\"\\n2. CSR (Compressed Sparse Row) Format:\")\n",
    "print(f\"   Data: {csr.data}\")\n",
    "print(f\"   Indices: {csr.indices}\")\n",
    "print(f\"   Indptr: {csr.indptr}\")\n",
    "\n",
    "print(\"\\n3. DOK (Dictionary of Keys) Format:\")\n",
    "print(f\"   Dictionary: {dict(dok)}\")\n",
    "\n",
    "print(\"\\nDense representation:\")\n",
    "print(csr.toarray())\n",
    "\n",
    "# Format comparison for different operations\n",
    "print(\"\\nBest format for different operations:\")\n",
    "print(\"- Matrix construction: COO or DOK\")\n",
    "print(\"- Matrix-vector multiplication: CSR or CSC\")\n",
    "print(\"- Row slicing: CSR\")\n",
    "print(\"- Column slicing: CSC\")\n",
    "print(\"- Element-wise operations: COO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Sparse Matrices Incrementally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Y-bus matrix incrementally\n",
    "# Typical pattern in power system analysis\n",
    "\n",
    "def build_ybus_sparse(bus_data, branch_data):\n",
    "    \"\"\"\n",
    "    Build Y-bus matrix using sparse format.\n",
    "    bus_data: list of bus indices\n",
    "    branch_data: list of (from_bus, to_bus, admittance)\n",
    "    \"\"\"\n",
    "    n = len(bus_data)\n",
    "    \n",
    "    # Use DOK format for incremental construction\n",
    "    ybus = sp.dok_matrix((n, n), dtype=complex)\n",
    "    \n",
    "    # Add branch admittances\n",
    "    for from_bus, to_bus, y in branch_data:\n",
    "        # Off-diagonal elements\n",
    "        ybus[from_bus, to_bus] -= y\n",
    "        ybus[to_bus, from_bus] -= y\n",
    "        # Diagonal elements\n",
    "        ybus[from_bus, from_bus] += y\n",
    "        ybus[to_bus, to_bus] += y\n",
    "    \n",
    "    # Convert to CSR for efficient operations\n",
    "    return ybus.tocsr()\n",
    "\n",
    "# Example: 6-bus system\n",
    "buses = list(range(6))\n",
    "branches = [\n",
    "    (0, 1, 2.0 - 6.0j),\n",
    "    (0, 4, 1.0 - 3.0j),\n",
    "    (1, 2, 1.5 - 4.5j),\n",
    "    (1, 3, 1.0 - 3.0j),\n",
    "    (1, 4, 0.5 - 1.5j),\n",
    "    (2, 3, 2.0 - 6.0j),\n",
    "    (3, 5, 1.0 - 3.0j),\n",
    "    (4, 5, 1.5 - 4.5j)\n",
    "]\n",
    "\n",
    "ybus_sparse = build_ybus_sparse(buses, branches)\n",
    "\n",
    "print(\"Y-bus matrix (sparse):\")\n",
    "print(f\"Shape: {ybus_sparse.shape}\")\n",
    "print(f\"Non-zero elements: {ybus_sparse.nnz}\")\n",
    "print(f\"Sparsity: {ybus_sparse.nnz / (ybus_sparse.shape[0]**2) * 100:.1f}%\")\n",
    "\n",
    "# Visualize sparsity pattern\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.spy(ybus_sparse, markersize=10)\n",
    "plt.title('Y-bus Sparsity Pattern')\n",
    "plt.xlabel('Column Index')\n",
    "plt.ylabel('Row Index')\n",
    "plt.show()\n",
    "\n",
    "# Show a few elements\n",
    "print(\"\\nSample elements:\")\n",
    "print(f\"Y[0,0] = {ybus_sparse[0,0]:.3f}\")\n",
    "print(f\"Y[0,1] = {ybus_sparse[0,1]:.3f}\")\n",
    "print(f\"Y[1,1] = {ybus_sparse[1,1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 1: Building a Large Sparse Network\n",
    ":class: dropdown\n",
    "\n",
    "Create a radial distribution network with 100 buses:\n",
    "1. Each bus connects to the next bus (bus i to bus i+1)\n",
    "2. Every 10th bus has a lateral connection to bus i+5\n",
    "3. Use random impedances: R between 0.01-0.05, X between 0.03-0.10\n",
    "4. Build the Y-bus matrix and analyze its sparsity\n",
    "5. Compare memory usage with a dense matrix\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Solution to Exercise 1\n",
    "n_buses = 100\n",
    "\n",
    "# Generate branch data\n",
    "branches = []\n",
    "\n",
    "# Main feeder connections\n",
    "for i in range(n_buses - 1):\n",
    "    r = np.random.uniform(0.01, 0.05)\n",
    "    x = np.random.uniform(0.03, 0.10)\n",
    "    z = r + 1j*x\n",
    "    y = 1/z  # Admittance\n",
    "    branches.append((i, i+1, y))\n",
    "\n",
    "# Lateral connections\n",
    "for i in range(0, n_buses-5, 10):\n",
    "    r = np.random.uniform(0.01, 0.05)\n",
    "    x = np.random.uniform(0.03, 0.10)\n",
    "    z = r + 1j*x\n",
    "    y = 1/z\n",
    "    branches.append((i, i+5, y))\n",
    "\n",
    "print(f\"Distribution Network:\")\n",
    "print(f\"Number of buses: {n_buses}\")\n",
    "print(f\"Number of branches: {len(branches)}\")\n",
    "\n",
    "# Build Y-bus matrix\n",
    "ybus = sp.dok_matrix((n_buses, n_buses), dtype=complex)\n",
    "\n",
    "for from_bus, to_bus, y in branches:\n",
    "    ybus[from_bus, to_bus] -= y\n",
    "    ybus[to_bus, from_bus] -= y\n",
    "    ybus[from_bus, from_bus] += y\n",
    "    ybus[to_bus, to_bus] += y\n",
    "\n",
    "# Convert to CSR\n",
    "ybus_csr = ybus.tocsr()\n",
    "\n",
    "# Analyze sparsity\n",
    "nnz = ybus_csr.nnz\n",
    "total_elements = n_buses * n_buses\n",
    "sparsity = nnz / total_elements * 100\n",
    "\n",
    "print(f\"\\nSparsity Analysis:\")\n",
    "print(f\"Non-zero elements: {nnz}\")\n",
    "print(f\"Total elements: {total_elements}\")\n",
    "print(f\"Sparsity: {sparsity:.2f}%\")\n",
    "print(f\"Average connections per bus: {nnz / n_buses:.1f}\")\n",
    "\n",
    "# Memory comparison\n",
    "# Dense matrix\n",
    "dense_size = n_buses * n_buses * 16  # 16 bytes for complex128\n",
    "# Sparse matrix (approximate)\n",
    "sparse_size = nnz * 16 + nnz * 4 + (n_buses + 1) * 4  # data + indices + indptr\n",
    "\n",
    "print(f\"\\nMemory Usage:\")\n",
    "print(f\"Dense matrix: {dense_size / 1024:.1f} KB\")\n",
    "print(f\"Sparse matrix: {sparse_size / 1024:.1f} KB\")\n",
    "print(f\"Memory savings: {(1 - sparse_size/dense_size)*100:.1f}%\")\n",
    "\n",
    "# Visualize sparsity pattern\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.spy(ybus_csr, markersize=1)\n",
    "plt.title(f'Distribution Network Y-bus Sparsity Pattern ({sparsity:.1f}% sparse)')\n",
    "plt.xlabel('Bus Index')\n",
    "plt.ylabel('Bus Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sparse Matrix Operations\n",
    "\n",
    "Efficient operations on sparse matrices are crucial for power system analysis. Let's explore common operations and their performance implications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix-Vector Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare sparse vs dense matrix-vector multiplication\n",
    "# This is fundamental for power flow iterations\n",
    "\n",
    "# Create a larger test case\n",
    "n = 500\n",
    "density = 0.01  # 1% non-zero elements\n",
    "\n",
    "# Generate random sparse matrix\n",
    "A_sparse = sp.random(n, n, density=density, format='csr')\n",
    "A_dense = A_sparse.toarray()\n",
    "\n",
    "# Random vector\n",
    "x = np.random.randn(n)\n",
    "\n",
    "# Time sparse multiplication\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    y_sparse = A_sparse @ x\n",
    "sparse_time = time.time() - start\n",
    "\n",
    "# Time dense multiplication\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    y_dense = A_dense @ x\n",
    "dense_time = time.time() - start\n",
    "\n",
    "print(f\"Matrix-Vector Multiplication ({n}×{n} matrix, {density*100:.1f}% density):\")\n",
    "print(f\"Sparse: {sparse_time*1000:.2f} ms\")\n",
    "print(f\"Dense: {dense_time*1000:.2f} ms\")\n",
    "print(f\"Speedup: {dense_time/sparse_time:.1f}x\")\n",
    "print(f\"\\nResults match: {np.allclose(y_sparse, y_dense)}\")\n",
    "\n",
    "# Analyze operation count\n",
    "flops_dense = 2 * n * n  # Multiplications and additions\n",
    "flops_sparse = 2 * A_sparse.nnz\n",
    "print(f\"\\nOperation count:\")\n",
    "print(f\"Dense: {flops_dense:,} FLOPs\")\n",
    "print(f\"Sparse: {flops_sparse:,} FLOPs\")\n",
    "print(f\"Reduction: {(1 - flops_sparse/flops_dense)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving Linear Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solving Ax = b with sparse matrices\n",
    "# Essential for power flow and state estimation\n",
    "\n",
    "# Create a symmetric positive definite sparse matrix\n",
    "# (like those in power system optimization)\n",
    "n = 200\n",
    "# Create a random sparse matrix\n",
    "A_temp = sp.random(n, n, density=0.05, format='csr')\n",
    "# Make it symmetric positive definite\n",
    "A_sparse = A_temp @ A_temp.T + sp.eye(n) * 10\n",
    "A_dense = A_sparse.toarray()\n",
    "\n",
    "# Right-hand side\n",
    "b = np.random.randn(n)\n",
    "\n",
    "# Method 1: Direct sparse solver\n",
    "start = time.time()\n",
    "x_sparse_direct = sp_linalg.spsolve(A_sparse, b)\n",
    "time_sparse_direct = time.time() - start\n",
    "\n",
    "# Method 2: Sparse LU decomposition\n",
    "start = time.time()\n",
    "lu = sp_linalg.splu(A_sparse.tocsc())\n",
    "x_sparse_lu = lu.solve(b)\n",
    "time_sparse_lu = time.time() - start\n",
    "\n",
    "# Method 3: Dense solver (for comparison)\n",
    "start = time.time()\n",
    "x_dense = np.linalg.solve(A_dense, b)\n",
    "time_dense = time.time() - start\n",
    "\n",
    "print(f\"Solving {n}×{n} linear system:\")\n",
    "print(f\"Sparse direct: {time_sparse_direct*1000:.2f} ms\")\n",
    "print(f\"Sparse LU: {time_sparse_lu*1000:.2f} ms\")\n",
    "print(f\"Dense: {time_dense*1000:.2f} ms\")\n",
    "print(f\"\\nSpeedup (sparse direct vs dense): {time_dense/time_sparse_direct:.1f}x\")\n",
    "\n",
    "# Verify solutions\n",
    "print(f\"\\nSolution verification:\")\n",
    "print(f\"Sparse direct vs dense: {np.allclose(x_sparse_direct, x_dense)}\")\n",
    "print(f\"Sparse LU vs dense: {np.allclose(x_sparse_lu, x_dense)}\")\n",
    "\n",
    "# Residual analysis\n",
    "residual_sparse = np.linalg.norm(A_sparse @ x_sparse_direct - b)\n",
    "residual_dense = np.linalg.norm(A_dense @ x_dense - b)\n",
    "print(f\"\\nResiduals:\")\n",
    "print(f\"Sparse: {residual_sparse:.2e}\")\n",
    "print(f\"Dense: {residual_dense:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative methods for very large systems\n",
    "# Used when direct methods become impractical\n",
    "\n",
    "# Create a larger system\n",
    "n = 1000\n",
    "# Diagonally dominant sparse matrix (convergence guaranteed)\n",
    "A = sp.random(n, n, density=0.01, format='csr')\n",
    "A = A @ A.T  # Make symmetric\n",
    "A = A + sp.eye(n) * (np.abs(A).sum(axis=1).max() + 1)  # Ensure diagonal dominance\n",
    "\n",
    "b = np.random.randn(n)\n",
    "\n",
    "# Compare different iterative methods\n",
    "methods = [\n",
    "    ('CG', sp_linalg.cg),         # Conjugate Gradient\n",
    "    ('GMRES', sp_linalg.gmres),   # Generalized Minimal Residual\n",
    "    ('BiCGSTAB', sp_linalg.bicgstab)  # Bi-Conjugate Gradient Stabilized\n",
    "]\n",
    "\n",
    "print(f\"Iterative Solvers for {n}×{n} system:\")\n",
    "print(f\"Matrix density: {A.nnz / (n*n) * 100:.2f}%\\n\")\n",
    "\n",
    "x_ref = sp_linalg.spsolve(A, b)  # Reference solution\n",
    "\n",
    "for name, solver in methods:\n",
    "    start = time.time()\n",
    "    x, info = solver(A, b, tol=1e-8, maxiter=100)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    if info == 0:\n",
    "        error = np.linalg.norm(x - x_ref) / np.linalg.norm(x_ref)\n",
    "        residual = np.linalg.norm(A @ x - b)\n",
    "        print(f\"{name:10s}: {elapsed*1000:6.2f} ms, error: {error:.2e}, residual: {residual:.2e}\")\n",
    "    else:\n",
    "        print(f\"{name:10s}: Failed to converge (info={info})\")\n",
    "\n",
    "# Demonstrate preconditioning effect\n",
    "print(\"\\nWith Preconditioning:\")\n",
    "# Simple diagonal preconditioner\n",
    "M = sp.diags(1.0 / A.diagonal())\n",
    "\n",
    "start = time.time()\n",
    "x_precond, info = sp_linalg.cg(A, b, M=M, tol=1e-8, maxiter=100)\n",
    "elapsed_precond = time.time() - start\n",
    "\n",
    "if info == 0:\n",
    "    error = np.linalg.norm(x_precond - x_ref) / np.linalg.norm(x_ref)\n",
    "    print(f\"CG with preconditioner: {elapsed_precond*1000:.2f} ms, error: {error:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 2: Sparse System Solution\n",
    ":class: dropdown\n",
    "\n",
    "Create and solve a sparse linear system representing a DC power flow problem:\n",
    "1. Create a 50-bus system with random connections (average 3 per bus)\n",
    "2. Build the B matrix (susceptance matrix) with random values between 5-20 p.u.\n",
    "3. Create power injection vector with random values between -1 and 1 p.u.\n",
    "4. Solve for bus angles using both direct and iterative methods\n",
    "5. Compare computation times and verify results\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Solution to Exercise 2\n",
    "np.random.seed(123)\n",
    "n_buses = 50\n",
    "avg_connections = 3\n",
    "\n",
    "# Create random connections\n",
    "connections = set()\n",
    "for i in range(n_buses):\n",
    "    # Connect to random buses\n",
    "    n_conn = np.random.poisson(avg_connections)\n",
    "    for _ in range(n_conn):\n",
    "        j = np.random.randint(0, n_buses)\n",
    "        if i != j:\n",
    "            connections.add((min(i,j), max(i,j)))\n",
    "\n",
    "connections = list(connections)\n",
    "print(f\"DC Power Flow Problem:\")\n",
    "print(f\"Buses: {n_buses}\")\n",
    "print(f\"Lines: {len(connections)}\")\n",
    "\n",
    "# Build B matrix\n",
    "B = sp.dok_matrix((n_buses, n_buses))\n",
    "\n",
    "for i, j in connections:\n",
    "    b_ij = np.random.uniform(5, 20)  # Susceptance\n",
    "    B[i, j] -= b_ij\n",
    "    B[j, i] -= b_ij\n",
    "    B[i, i] += b_ij\n",
    "    B[j, j] += b_ij\n",
    "\n",
    "B = B.tocsr()\n",
    "\n",
    "# Power injections (exclude slack bus)\n",
    "P = np.random.uniform(-1, 1, n_buses)\n",
    "P[0] = 0  # Slack bus\n",
    "\n",
    "# Remove slack bus from system\n",
    "B_reduced = B[1:, 1:]\n",
    "P_reduced = P[1:]\n",
    "\n",
    "print(f\"\\nSystem matrix: {B_reduced.shape}\")\n",
    "print(f\"Sparsity: {B_reduced.nnz / (B_reduced.shape[0]**2) * 100:.1f}%\")\n",
    "\n",
    "# Method 1: Direct solver\n",
    "start = time.time()\n",
    "theta_direct = sp_linalg.spsolve(B_reduced, P_reduced)\n",
    "time_direct = time.time() - start\n",
    "\n",
    "# Method 2: CG solver\n",
    "start = time.time()\n",
    "theta_cg, info_cg = sp_linalg.cg(B_reduced, P_reduced, tol=1e-10)\n",
    "time_cg = time.time() - start\n",
    "\n",
    "# Method 3: LU decomposition\n",
    "start = time.time()\n",
    "lu = sp_linalg.splu(B_reduced.tocsc())\n",
    "theta_lu = lu.solve(P_reduced)\n",
    "time_lu = time.time() - start\n",
    "\n",
    "print(f\"\\nSolution times:\")\n",
    "print(f\"Direct: {time_direct*1000:.3f} ms\")\n",
    "print(f\"CG: {time_cg*1000:.3f} ms (converged: {info_cg == 0})\")\n",
    "print(f\"LU: {time_lu*1000:.3f} ms\")\n",
    "\n",
    "# Verify solutions\n",
    "print(f\"\\nSolution verification:\")\n",
    "print(f\"Direct vs CG: max diff = {np.max(np.abs(theta_direct - theta_cg)):.2e}\")\n",
    "print(f\"Direct vs LU: max diff = {np.max(np.abs(theta_direct - theta_lu)):.2e}\")\n",
    "\n",
    "# Check power balance\n",
    "theta_full = np.zeros(n_buses)\n",
    "theta_full[1:] = theta_direct\n",
    "\n",
    "# Calculate flows and verify power balance\n",
    "P_calc = B @ theta_full\n",
    "P[0] = P_calc[0]  # Slack bus power\n",
    "\n",
    "print(f\"\\nPower balance check:\")\n",
    "print(f\"Total generation: {P[P>0].sum():.3f} p.u.\")\n",
    "print(f\"Total load: {-P[P<0].sum():.3f} p.u.\")\n",
    "print(f\"Mismatch: {P.sum():.2e} p.u.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Advanced Linear Algebra\n",
    "\n",
    "Module 04 requires understanding of matrix factorizations and numerical stability. Let's explore these concepts with power system examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LU Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LU factorization for repeated solutions\n",
    "# Common in power flow where we solve with same matrix, different RHS\n",
    "\n",
    "# Create a test matrix (simplified Y-bus)\n",
    "n = 10\n",
    "Y = sp.random(n, n, density=0.3, format='csr')\n",
    "Y = Y + Y.T  # Make symmetric\n",
    "Y = Y + sp.eye(n) * 5  # Ensure non-singular\n",
    "\n",
    "# Multiple right-hand sides (different current injections)\n",
    "n_cases = 100\n",
    "I_injections = np.random.randn(n, n_cases) + 1j * np.random.randn(n, n_cases)\n",
    "\n",
    "print(\"Solving multiple right-hand sides:\")\n",
    "print(f\"Matrix size: {n}×{n}\")\n",
    "print(f\"Number of RHS vectors: {n_cases}\\n\")\n",
    "\n",
    "# Method 1: Solve each independently\n",
    "start = time.time()\n",
    "V_independent = np.zeros((n, n_cases), dtype=complex)\n",
    "for i in range(n_cases):\n",
    "    V_independent[:, i] = sp_linalg.spsolve(Y, I_injections[:, i])\n",
    "time_independent = time.time() - start\n",
    "\n",
    "# Method 2: LU factorization once, solve multiple times\n",
    "start = time.time()\n",
    "lu = sp_linalg.splu(Y.tocsc())\n",
    "time_factor = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "V_lu = np.zeros((n, n_cases), dtype=complex)\n",
    "for i in range(n_cases):\n",
    "    V_lu[:, i] = lu.solve(I_injections[:, i])\n",
    "time_solve = time.time() - start\n",
    "\n",
    "print(f\"Independent solutions: {time_independent*1000:.1f} ms\")\n",
    "print(f\"LU factorization: {time_factor*1000:.1f} ms\")\n",
    "print(f\"LU back-substitution: {time_solve*1000:.1f} ms\")\n",
    "print(f\"Total LU time: {(time_factor + time_solve)*1000:.1f} ms\")\n",
    "print(f\"\\nSpeedup: {time_independent/(time_factor + time_solve):.1f}x\")\n",
    "\n",
    "# Verify results\n",
    "print(f\"\\nResults match: {np.allclose(V_independent, V_lu)}\")\n",
    "\n",
    "# Analyze LU factors\n",
    "print(f\"\\nLU factorization analysis:\")\n",
    "print(f\"Original matrix non-zeros: {Y.nnz}\")\n",
    "print(f\"L factor non-zeros: {lu.L.nnz}\")\n",
    "print(f\"U factor non-zeros: {lu.U.nnz}\")\n",
    "print(f\"Fill-in: {(lu.L.nnz + lu.U.nnz - Y.nnz) / Y.nnz * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Conditioning and Numerical Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding condition numbers and their impact\n",
    "# Important for power flow convergence\n",
    "\n",
    "# Create matrices with different condition numbers\n",
    "n = 50\n",
    "\n",
    "# Well-conditioned matrix\n",
    "A_good = sp.random(n, n, density=0.1)\n",
    "A_good = A_good @ A_good.T + sp.eye(n) * 10\n",
    "\n",
    "# Poorly-conditioned matrix\n",
    "A_bad = sp.random(n, n, density=0.1)\n",
    "A_bad = A_bad @ A_bad.T + sp.eye(n) * 0.001\n",
    "\n",
    "# Calculate condition numbers\n",
    "cond_good = np.linalg.cond(A_good.toarray())\n",
    "cond_bad = np.linalg.cond(A_bad.toarray())\n",
    "\n",
    "print(\"Matrix Conditioning Analysis:\")\n",
    "print(f\"Well-conditioned matrix: κ = {cond_good:.2e}\")\n",
    "print(f\"Poorly-conditioned matrix: κ = {cond_bad:.2e}\")\n",
    "\n",
    "# Test sensitivity to perturbations\n",
    "b = np.random.randn(n)\n",
    "x_good = sp_linalg.spsolve(A_good, b)\n",
    "x_bad = sp_linalg.spsolve(A_bad, b)\n",
    "\n",
    "# Add small perturbation to b\n",
    "delta_b = np.random.randn(n) * 1e-6\n",
    "b_perturbed = b + delta_b\n",
    "\n",
    "x_good_pert = sp_linalg.spsolve(A_good, b_perturbed)\n",
    "x_bad_pert = sp_linalg.spsolve(A_bad, b_perturbed)\n",
    "\n",
    "# Calculate relative changes\n",
    "rel_change_b = np.linalg.norm(delta_b) / np.linalg.norm(b)\n",
    "rel_change_x_good = np.linalg.norm(x_good_pert - x_good) / np.linalg.norm(x_good)\n",
    "rel_change_x_bad = np.linalg.norm(x_bad_pert - x_bad) / np.linalg.norm(x_bad)\n",
    "\n",
    "print(f\"\\nPerturbation Analysis:\")\n",
    "print(f\"Relative change in b: {rel_change_b:.2e}\")\n",
    "print(f\"Relative change in x (good): {rel_change_x_good:.2e}\")\n",
    "print(f\"Relative change in x (bad): {rel_change_x_bad:.2e}\")\n",
    "print(f\"\\nAmplification factor (good): {rel_change_x_good/rel_change_b:.1f}\")\n",
    "print(f\"Amplification factor (bad): {rel_change_x_bad/rel_change_b:.1f}\")\n",
    "\n",
    "# Iterative refinement for ill-conditioned systems\n",
    "def iterative_refinement(A, b, x0, max_iter=5):\n",
    "    \"\"\"Improve solution accuracy through iterative refinement\"\"\"\n",
    "    x = x0.copy()\n",
    "    for i in range(max_iter):\n",
    "        r = b - A @ x\n",
    "        delta_x = sp_linalg.spsolve(A, r)\n",
    "        x = x + delta_x\n",
    "        if np.linalg.norm(delta_x) < 1e-10:\n",
    "            break\n",
    "    return x, i+1\n",
    "\n",
    "# Apply to poorly-conditioned system\n",
    "x_refined, iterations = iterative_refinement(A_bad, b, x_bad)\n",
    "residual_original = np.linalg.norm(A_bad @ x_bad - b)\n",
    "residual_refined = np.linalg.norm(A_bad @ x_refined - b)\n",
    "\n",
    "print(f\"\\nIterative Refinement:\")\n",
    "print(f\"Original residual: {residual_original:.2e}\")\n",
    "print(f\"Refined residual: {residual_refined:.2e}\")\n",
    "print(f\"Improvement factor: {residual_original/residual_refined:.1f}\")\n",
    "print(f\"Iterations: {iterations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvalue Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigenvalue analysis for system stability\n",
    "# Used in small-signal stability studies\n",
    "\n",
    "# Create a state matrix for a simple power system model\n",
    "# 2-state model per generator: angle and speed\n",
    "n_gen = 3\n",
    "n_states = 2 * n_gen\n",
    "\n",
    "# System parameters\n",
    "H = np.array([5.0, 4.0, 3.0])  # Inertia constants\n",
    "D = np.array([1.0, 0.8, 1.2])  # Damping coefficients\n",
    "\n",
    "# Simplified state matrix (demonstration)\n",
    "A = np.zeros((n_states, n_states))\n",
    "\n",
    "# Fill state matrix\n",
    "for i in range(n_gen):\n",
    "    # Speed-angle relationship\n",
    "    A[2*i, 2*i+1] = 377.0  # 2*pi*60 rad/s\n",
    "    # Damping\n",
    "    A[2*i+1, 2*i+1] = -D[i] / (2*H[i])\n",
    "    # Synchronizing torque (simplified)\n",
    "    A[2*i+1, 2*i] = -1.0 / (2*H[i])\n",
    "\n",
    "# Add coupling between generators\n",
    "coupling = 0.5\n",
    "for i in range(n_gen):\n",
    "    for j in range(n_gen):\n",
    "        if i != j:\n",
    "            A[2*i+1, 2*j] = coupling / (2*H[i])\n",
    "\n",
    "print(\"Small-Signal Stability Analysis\")\n",
    "print(f\"System: {n_gen} generators, {n_states} states\\n\")\n",
    "\n",
    "# Calculate eigenvalues\n",
    "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
    "\n",
    "# Analyze stability\n",
    "print(\"Eigenvalue Analysis:\")\n",
    "print(\"Mode   Real Part   Imag Part   Frequency(Hz)   Damping(%)   Stability\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, eigval in enumerate(eigenvalues):\n",
    "    real_part = eigval.real\n",
    "    imag_part = eigval.imag\n",
    "    \n",
    "    if abs(imag_part) > 1e-6:  # Oscillatory mode\n",
    "        frequency = abs(imag_part) / (2 * np.pi)\n",
    "        damping = -real_part / abs(eigval) * 100\n",
    "        stability = \"Stable\" if real_part < 0 else \"UNSTABLE\"\n",
    "    else:  # Non-oscillatory mode\n",
    "        frequency = 0\n",
    "        damping = 100 if real_part < 0 else 0\n",
    "        stability = \"Stable\" if real_part < 0 else \"UNSTABLE\"\n",
    "    \n",
    "    print(f\"{i+1:4d}   {real_part:9.4f}   {imag_part:9.4f}   {frequency:11.3f}   \"\n",
    "          f\"{damping:9.1f}   {stability}\")\n",
    "\n",
    "# Participation factors\n",
    "print(\"\\nParticipation Factors (dominant modes):\")\n",
    "# Find oscillatory modes\n",
    "osc_modes = np.where(np.abs(eigenvalues.imag) > 1e-6)[0]\n",
    "\n",
    "if len(osc_modes) > 0:\n",
    "    mode = osc_modes[0]  # First oscillatory mode\n",
    "    eigvec = eigenvectors[:, mode]\n",
    "    \n",
    "    # Normalize by maximum\n",
    "    participation = np.abs(eigvec) / np.max(np.abs(eigvec))\n",
    "    \n",
    "    print(f\"\\nMode {mode+1} participation:\")\n",
    "    for i in range(n_gen):\n",
    "        angle_part = participation[2*i]\n",
    "        speed_part = participation[2*i+1]\n",
    "        print(f\"Generator {i+1}: angle={angle_part:.3f}, speed={speed_part:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 3: Eigenvalue Sensitivity\n",
    ":class: dropdown\n",
    "\n",
    "Analyze how system parameters affect eigenvalues:\n",
    "1. Create a 2×2 system matrix representing a single-machine infinite bus\n",
    "2. Vary the damping coefficient from 0.5 to 2.0\n",
    "3. Calculate eigenvalues for each damping value\n",
    "4. Plot the eigenvalue trajectories in the complex plane\n",
    "5. Identify the critical damping value\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Solution to Exercise 3\n",
    "# Single machine infinite bus model\n",
    "# States: [delta, omega] (angle and speed deviation)\n",
    "\n",
    "# Fixed parameters\n",
    "H = 5.0  # Inertia constant\n",
    "omega_s = 377.0  # Synchronous speed (rad/s)\n",
    "P_max = 1.0  # Maximum power transfer\n",
    "delta_0 = np.pi/6  # Initial operating angle (30 degrees)\n",
    "\n",
    "# Linearized synchronizing torque coefficient\n",
    "K_s = P_max * np.cos(delta_0)\n",
    "\n",
    "# Vary damping\n",
    "D_values = np.linspace(0.5, 2.0, 50)\n",
    "eigenvalues_all = []\n",
    "\n",
    "for D in D_values:\n",
    "    # State matrix\n",
    "    A = np.array([\n",
    "        [0, omega_s],\n",
    "        [-K_s/(2*H), -D/(2*H)]\n",
    "    ])\n",
    "    \n",
    "    eigvals = np.linalg.eigvals(A)\n",
    "    eigenvalues_all.append(eigvals)\n",
    "\n",
    "eigenvalues_all = np.array(eigenvalues_all)\n",
    "\n",
    "# Plot eigenvalue trajectories\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot in complex plane\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(eigenvalues_all[:, 0].real, eigenvalues_all[:, 0].imag, 'b-', linewidth=2)\n",
    "plt.plot(eigenvalues_all[:, 1].real, eigenvalues_all[:, 1].imag, 'r-', linewidth=2)\n",
    "plt.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "plt.axvline(x=0, color='k', linestyle='--', alpha=0.3)\n",
    "plt.xlabel('Real Part')\n",
    "plt.ylabel('Imaginary Part')\n",
    "plt.title('Eigenvalue Trajectories')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Damping ratio vs D\n",
    "plt.subplot(2, 2, 2)\n",
    "damping_ratios = []\n",
    "frequencies = []\n",
    "\n",
    "for eigvals in eigenvalues_all:\n",
    "    if np.abs(eigvals[0].imag) > 1e-6:  # Oscillatory\n",
    "        damping_ratio = -eigvals[0].real / np.abs(eigvals[0])\n",
    "        frequency = np.abs(eigvals[0].imag) / (2 * np.pi)\n",
    "    else:  # Critically or over-damped\n",
    "        damping_ratio = 1.0\n",
    "        frequency = 0\n",
    "    damping_ratios.append(damping_ratio)\n",
    "    frequencies.append(frequency)\n",
    "\n",
    "plt.plot(D_values, damping_ratios, 'g-', linewidth=2)\n",
    "plt.axhline(y=0.707, color='r', linestyle='--', label='ζ = 0.707')\n",
    "plt.xlabel('Damping Coefficient D')\n",
    "plt.ylabel('Damping Ratio ζ')\n",
    "plt.title('Damping Ratio vs Damping Coefficient')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "# Frequency vs D\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(D_values, frequencies, 'm-', linewidth=2)\n",
    "plt.xlabel('Damping Coefficient D')\n",
    "plt.ylabel('Oscillation Frequency (Hz)')\n",
    "plt.title('Natural Frequency vs Damping')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Real parts vs D\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(D_values, eigenvalues_all[:, 0].real, 'b-', linewidth=2, label='λ₁')\n",
    "plt.plot(D_values, eigenvalues_all[:, 1].real, 'r-', linewidth=2, label='λ₂')\n",
    "plt.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "plt.xlabel('Damping Coefficient D')\n",
    "plt.ylabel('Real Part of Eigenvalue')\n",
    "plt.title('Stability vs Damping')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find critical damping\n",
    "critical_idx = np.where(np.array(frequencies) < 0.01)[0]\n",
    "if len(critical_idx) > 0:\n",
    "    D_critical = D_values[critical_idx[0]]\n",
    "    print(f\"Critical damping occurs at D ≈ {D_critical:.3f}\")\n",
    "    \n",
    "    # Theoretical critical damping\n",
    "    D_critical_theory = 2 * np.sqrt(2 * H * K_s)\n",
    "    print(f\"Theoretical critical damping: D = {D_critical_theory:.3f}\")\n",
    "    print(f\"Error: {abs(D_critical - D_critical_theory):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance Optimization\n",
    "\n",
    "Efficient NumPy code is crucial for large-scale power system analysis. Let's explore optimization techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Layout and Cache Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding memory layout impact on performance\n",
    "n = 1000\n",
    "m = 1000\n",
    "\n",
    "# Create test matrices\n",
    "A = np.random.randn(n, m)\n",
    "B = np.random.randn(m, n)\n",
    "\n",
    "# Row-major (C-order) vs Column-major (Fortran-order)\n",
    "A_C = np.ascontiguousarray(A)  # C-order\n",
    "A_F = np.asfortranarray(A)     # Fortran-order\n",
    "\n",
    "print(\"Memory Layout Performance:\")\n",
    "print(f\"Matrix shape: {A.shape}\")\n",
    "\n",
    "# Test 1: Row-wise operations\n",
    "print(\"\\n1. Row-wise sum:\")\n",
    "# C-order (row-major)\n",
    "start = time.time()\n",
    "for _ in range(10):\n",
    "    row_sum_C = A_C.sum(axis=1)\n",
    "time_C = time.time() - start\n",
    "\n",
    "# F-order (column-major)\n",
    "start = time.time()\n",
    "for _ in range(10):\n",
    "    row_sum_F = A_F.sum(axis=1)\n",
    "time_F = time.time() - start\n",
    "\n",
    "print(f\"   C-order: {time_C*1000:.2f} ms\")\n",
    "print(f\"   F-order: {time_F*1000:.2f} ms\")\n",
    "print(f\"   Speedup: {time_F/time_C:.2f}x\")\n",
    "\n",
    "# Test 2: Column-wise operations\n",
    "print(\"\\n2. Column-wise sum:\")\n",
    "# C-order\n",
    "start = time.time()\n",
    "for _ in range(10):\n",
    "    col_sum_C = A_C.sum(axis=0)\n",
    "time_C = time.time() - start\n",
    "\n",
    "# F-order\n",
    "start = time.time()\n",
    "for _ in range(10):\n",
    "    col_sum_F = A_F.sum(axis=0)\n",
    "time_F = time.time() - start\n",
    "\n",
    "print(f\"   C-order: {time_C*1000:.2f} ms\")\n",
    "print(f\"   F-order: {time_F*1000:.2f} ms\")\n",
    "print(f\"   Speedup: {time_C/time_F:.2f}x\")\n",
    "\n",
    "# Test 3: Matrix multiplication\n",
    "print(\"\\n3. Matrix multiplication (A @ B):\")\n",
    "# Default\n",
    "start = time.time()\n",
    "C1 = A @ B\n",
    "time_default = time.time() - start\n",
    "\n",
    "# Optimized order\n",
    "start = time.time()\n",
    "C2 = np.ascontiguousarray(A) @ np.asfortranarray(B)\n",
    "time_optimized = time.time() - start\n",
    "\n",
    "print(f\"   Default: {time_default*1000:.2f} ms\")\n",
    "print(f\"   Optimized: {time_optimized*1000:.2f} ms\")\n",
    "print(f\"   Speedup: {time_default/time_optimized:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing power system calculations\n",
    "# Example: Calculate power losses for all lines\n",
    "\n",
    "# Network data\n",
    "n_lines = 1000\n",
    "V_from = np.random.uniform(0.95, 1.05, n_lines) * np.exp(1j * np.random.uniform(-0.1, 0.1, n_lines))\n",
    "V_to = np.random.uniform(0.95, 1.05, n_lines) * np.exp(1j * np.random.uniform(-0.1, 0.1, n_lines))\n",
    "Y_lines = np.random.uniform(5, 20, n_lines) - 1j * np.random.uniform(15, 60, n_lines)\n",
    "\n",
    "print(f\"Power Loss Calculation for {n_lines} lines:\")\n",
    "\n",
    "# Method 1: Loop-based (slow)\n",
    "def calculate_losses_loop(V_from, V_to, Y_lines):\n",
    "    losses = np.zeros(len(V_from))\n",
    "    for i in range(len(V_from)):\n",
    "        I = (V_from[i] - V_to[i]) * Y_lines[i]\n",
    "        losses[i] = np.real(I * np.conj(I) / Y_lines[i])\n",
    "    return losses\n",
    "\n",
    "# Method 2: Vectorized\n",
    "def calculate_losses_vectorized(V_from, V_to, Y_lines):\n",
    "    I = (V_from - V_to) * Y_lines\n",
    "    return np.real(I * np.conj(I) / Y_lines)\n",
    "\n",
    "# Method 3: Optimized vectorized\n",
    "def calculate_losses_optimized(V_from, V_to, Y_lines):\n",
    "    V_diff = V_from - V_to\n",
    "    I_squared = np.abs(V_diff)**2 * np.abs(Y_lines)**2\n",
    "    return I_squared / np.abs(Y_lines)\n",
    "\n",
    "# Time comparison\n",
    "start = time.time()\n",
    "losses_loop = calculate_losses_loop(V_from, V_to, Y_lines)\n",
    "time_loop = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "losses_vec = calculate_losses_vectorized(V_from, V_to, Y_lines)\n",
    "time_vec = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "losses_opt = calculate_losses_optimized(V_from, V_to, Y_lines)\n",
    "time_opt = time.time() - start\n",
    "\n",
    "print(f\"\\nLoop-based: {time_loop*1000:.2f} ms\")\n",
    "print(f\"Vectorized: {time_vec*1000:.2f} ms (speedup: {time_loop/time_vec:.1f}x)\")\n",
    "print(f\"Optimized: {time_opt*1000:.2f} ms (speedup: {time_loop/time_opt:.1f}x)\")\n",
    "\n",
    "# Verify results\n",
    "print(f\"\\nResults match:\")\n",
    "print(f\"Loop vs vectorized: {np.allclose(losses_loop, losses_vec)}\")\n",
    "print(f\"Loop vs optimized: {np.allclose(losses_loop, losses_opt, rtol=1e-5)}\")\n",
    "\n",
    "# Total system losses\n",
    "print(f\"\\nTotal system losses: {np.sum(losses_vec):.2f} MW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NumPy's Built-in Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leveraging optimized NumPy functions\n",
    "# Example: Finding constrained generators\n",
    "\n",
    "# Generator data\n",
    "n_gen = 100\n",
    "P_min = np.random.uniform(10, 50, n_gen)\n",
    "P_max = P_min + np.random.uniform(50, 200, n_gen)\n",
    "P_current = np.random.uniform(0, 1, n_gen) * (P_max - P_min) + P_min\n",
    "\n",
    "# Add some generators at limits\n",
    "P_current[::10] = P_min[::10]  # Every 10th at min\n",
    "P_current[5::10] = P_max[5::10]  # Every 10th at max\n",
    "\n",
    "print(\"Finding Constrained Generators:\")\n",
    "\n",
    "# Method 1: Loop with conditions\n",
    "def find_constrained_loop(P_current, P_min, P_max, tol=1e-6):\n",
    "    at_min = []\n",
    "    at_max = []\n",
    "    unconstrained = []\n",
    "    \n",
    "    for i in range(len(P_current)):\n",
    "        if abs(P_current[i] - P_min[i]) < tol:\n",
    "            at_min.append(i)\n",
    "        elif abs(P_current[i] - P_max[i]) < tol:\n",
    "            at_max.append(i)\n",
    "        else:\n",
    "            unconstrained.append(i)\n",
    "    \n",
    "    return at_min, at_max, unconstrained\n",
    "\n",
    "# Method 2: NumPy boolean indexing\n",
    "def find_constrained_numpy(P_current, P_min, P_max, tol=1e-6):\n",
    "    at_min = np.where(np.abs(P_current - P_min) < tol)[0]\n",
    "    at_max = np.where(np.abs(P_current - P_max) < tol)[0]\n",
    "    constrained = np.concatenate([at_min, at_max])\n",
    "    unconstrained = np.setdiff1d(np.arange(len(P_current)), constrained)\n",
    "    \n",
    "    return at_min, at_max, unconstrained\n",
    "\n",
    "# Time comparison\n",
    "n_runs = 1000\n",
    "\n",
    "start = time.time()\n",
    "for _ in range(n_runs):\n",
    "    min1, max1, free1 = find_constrained_loop(P_current, P_min, P_max)\n",
    "time_loop = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "for _ in range(n_runs):\n",
    "    min2, max2, free2 = find_constrained_numpy(P_current, P_min, P_max)\n",
    "time_numpy = time.time() - start\n",
    "\n",
    "print(f\"\\nLoop method: {time_loop*1000:.2f} ms\")\n",
    "print(f\"NumPy method: {time_numpy*1000:.2f} ms\")\n",
    "print(f\"Speedup: {time_loop/time_numpy:.1f}x\")\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"Generators at min: {len(min2)}\")\n",
    "print(f\"Generators at max: {len(max2)}\")\n",
    "print(f\"Unconstrained: {len(free2)}\")\n",
    "\n",
    "# Additional analysis using NumPy functions\n",
    "margin_to_max = P_max - P_current\n",
    "margin_to_min = P_current - P_min\n",
    "\n",
    "print(f\"\\nMargin Analysis:\")\n",
    "print(f\"Average upward margin: {np.mean(margin_to_max):.1f} MW\")\n",
    "print(f\"Average downward margin: {np.mean(margin_to_min):.1f} MW\")\n",
    "print(f\"Total upward reserve: {np.sum(margin_to_max):.0f} MW\")\n",
    "print(f\"Total downward reserve: {np.sum(margin_to_min):.0f} MW\")\n",
    "\n",
    "# Generators close to limits\n",
    "threshold = 5.0  # MW\n",
    "near_max = np.sum(margin_to_max < threshold)\n",
    "near_min = np.sum(margin_to_min < threshold)\n",
    "print(f\"\\nGenerators within {threshold} MW of limits:\")\n",
    "print(f\"Near max: {near_max}\")\n",
    "print(f\"Near min: {near_min}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 4: Performance Optimization Challenge\n",
    ":class: dropdown\n",
    "\n",
    "Optimize a power flow mismatch calculation:\n",
    "1. Create a 100-bus system with random Y-bus (5% density)\n",
    "2. Generate random voltage magnitudes and angles\n",
    "3. Calculate power mismatches P_specified - P_calculated\n",
    "4. Implement three versions: loop-based, basic vectorized, optimized\n",
    "5. Compare performance and verify correctness\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Solution to Exercise 4\n",
    "n = 100\n",
    "density = 0.05\n",
    "\n",
    "# Create Y-bus\n",
    "Y_sparse = sp.random(n, n, density=density, dtype=complex)\n",
    "Y_sparse = Y_sparse + Y_sparse.T  # Make symmetric\n",
    "# Make diagonally dominant\n",
    "for i in range(n):\n",
    "    Y_sparse[i, i] = np.sum(np.abs(Y_sparse[i, :])) + 1\n",
    "\n",
    "Y_dense = Y_sparse.toarray()\n",
    "\n",
    "# Voltage data\n",
    "V_mag = np.random.uniform(0.95, 1.05, n)\n",
    "V_angle = np.random.uniform(-0.2, 0.2, n)\n",
    "V_complex = V_mag * np.exp(1j * V_angle)\n",
    "\n",
    "# Specified power\n",
    "P_spec = np.random.uniform(-2, 2, n)\n",
    "P_spec[0] = 0  # Slack bus\n",
    "\n",
    "print(\"Power Flow Mismatch Calculation:\")\n",
    "print(f\"System: {n} buses, {Y_sparse.nnz} non-zero Y-bus elements\\n\")\n",
    "\n",
    "# Method 1: Loop-based\n",
    "def mismatch_loop(V_complex, Y, P_spec):\n",
    "    n = len(V_complex)\n",
    "    P_calc = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if Y[i, j] != 0:\n",
    "                P_calc[i] += np.real(V_complex[i] * np.conj(Y[i, j] * V_complex[j]))\n",
    "    \n",
    "    return P_spec - P_calc\n",
    "\n",
    "# Method 2: Basic vectorized\n",
    "def mismatch_vectorized(V_complex, Y, P_spec):\n",
    "    S_calc = V_complex * np.conj(Y @ V_complex)\n",
    "    P_calc = S_calc.real\n",
    "    return P_spec - P_calc\n",
    "\n",
    "# Method 3: Optimized with sparse\n",
    "def mismatch_optimized(V_complex, Y_sparse, P_spec):\n",
    "    # Use sparse matrix multiplication\n",
    "    I_calc = Y_sparse @ V_complex\n",
    "    S_calc = V_complex * np.conj(I_calc)\n",
    "    return P_spec - S_calc.real\n",
    "\n",
    "# Time comparison\n",
    "n_runs = 10\n",
    "\n",
    "# Loop method (only run once due to slowness)\n",
    "start = time.time()\n",
    "mismatch1 = mismatch_loop(V_complex, Y_dense, P_spec)\n",
    "time_loop = time.time() - start\n",
    "\n",
    "# Vectorized method\n",
    "start = time.time()\n",
    "for _ in range(n_runs):\n",
    "    mismatch2 = mismatch_vectorized(V_complex, Y_dense, P_spec)\n",
    "time_vec = (time.time() - start) / n_runs\n",
    "\n",
    "# Optimized method\n",
    "start = time.time()\n",
    "for _ in range(n_runs):\n",
    "    mismatch3 = mismatch_optimized(V_complex, Y_sparse, P_spec)\n",
    "time_opt = (time.time() - start) / n_runs\n",
    "\n",
    "print(f\"Performance Comparison:\")\n",
    "print(f\"Loop-based: {time_loop*1000:.2f} ms\")\n",
    "print(f\"Vectorized: {time_vec*1000:.2f} ms (speedup: {time_loop/time_vec:.1f}x)\")\n",
    "print(f\"Optimized: {time_opt*1000:.2f} ms (speedup: {time_loop/time_opt:.1f}x)\")\n",
    "\n",
    "# Verify correctness\n",
    "print(f\"\\nVerification:\")\n",
    "print(f\"Loop vs vectorized: max diff = {np.max(np.abs(mismatch1 - mismatch2)):.2e}\")\n",
    "print(f\"Loop vs optimized: max diff = {np.max(np.abs(mismatch1 - mismatch3)):.2e}\")\n",
    "\n",
    "# Analyze mismatches\n",
    "print(f\"\\nMismatch Statistics:\")\n",
    "print(f\"Maximum mismatch: {np.max(np.abs(mismatch3)):.3f} p.u.\")\n",
    "print(f\"Average mismatch: {np.mean(np.abs(mismatch3)):.3f} p.u.\")\n",
    "print(f\"RMS mismatch: {np.sqrt(np.mean(mismatch3**2)):.3f} p.u.\")\n",
    "\n",
    "# Memory usage comparison\n",
    "print(f\"\\nMemory Usage:\")\n",
    "print(f\"Dense Y-bus: {Y_dense.nbytes / 1024:.1f} KB\")\n",
    "print(f\"Sparse Y-bus: {(Y_sparse.data.nbytes + Y_sparse.indices.nbytes + Y_sparse.indptr.nbytes) / 1024:.1f} KB\")\n",
    "print(f\"Memory savings: {(1 - (Y_sparse.data.nbytes + Y_sparse.indices.nbytes + Y_sparse.indptr.nbytes) / Y_dense.nbytes) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Integration with Module 04\n",
    "\n",
    "Let's explore specific techniques that directly prepare you for Module 04's numerical methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jacobian Matrix Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Jacobian matrices for Newton-Raphson\n",
    "# Essential for Module 04's power flow implementation\n",
    "\n",
    "def build_jacobian_template(n_buses, bus_types, Y_sparse):\n",
    "    \"\"\"\n",
    "    Build Jacobian matrix structure for power flow.\n",
    "    bus_types: 0=slack, 1=PV, 2=PQ\n",
    "    \"\"\"\n",
    "    # Identify bus indices\n",
    "    pq_buses = np.where(bus_types == 2)[0]\n",
    "    pv_buses = np.where(bus_types == 1)[0]\n",
    "    non_slack = np.concatenate([pv_buses, pq_buses])\n",
    "    \n",
    "    n_pq = len(pq_buses)\n",
    "    n_pv = len(pv_buses)\n",
    "    \n",
    "    # Jacobian sub-matrices dimensions\n",
    "    # J = [J11 J12]  where J11: dP/dθ, J12: dP/dV\n",
    "    #     [J21 J22]        J21: dQ/dθ, J22: dQ/dV\n",
    "    \n",
    "    print(f\"Jacobian Structure:\")\n",
    "    print(f\"PV buses: {n_pv}, PQ buses: {n_pq}\")\n",
    "    print(f\"J11: {n_pv + n_pq} × {n_pv + n_pq} (dP/dθ)\")\n",
    "    print(f\"J12: {n_pv + n_pq} × {n_pq} (dP/dV)\")\n",
    "    print(f\"J21: {n_pq} × {n_pv + n_pq} (dQ/dθ)\")\n",
    "    print(f\"J22: {n_pq} × {n_pq} (dQ/dV)\")\n",
    "    \n",
    "    # Determine sparsity pattern from Y-bus\n",
    "    # Jacobian element (i,j) is non-zero if Y[i,j] is non-zero\n",
    "    rows = []\n",
    "    cols = []\n",
    "    \n",
    "    # J11 pattern (all non-slack buses)\n",
    "    for i_idx, i in enumerate(non_slack):\n",
    "        for j_idx, j in enumerate(non_slack):\n",
    "            if Y_sparse[i, j] != 0:\n",
    "                rows.append(i_idx)\n",
    "                cols.append(j_idx)\n",
    "    \n",
    "    n_jacobian = len(non_slack) + n_pq\n",
    "    J_pattern = sp.csr_matrix(\n",
    "        (np.ones(len(rows)), (rows, cols)),\n",
    "        shape=(len(non_slack), len(non_slack))\n",
    "    )\n",
    "    \n",
    "    return J_pattern, non_slack, pq_buses\n",
    "\n",
    "# Example system\n",
    "n = 10\n",
    "bus_types = np.array([0, 1, 1, 2, 2, 2, 2, 2, 2, 2])  # 1 slack, 2 PV, 7 PQ\n",
    "\n",
    "# Create sparse Y-bus\n",
    "Y_bus = sp.random(n, n, density=0.3, dtype=complex)\n",
    "Y_bus = Y_bus + Y_bus.T\n",
    "\n",
    "J_pattern, non_slack, pq_buses = build_jacobian_template(n, bus_types, Y_bus)\n",
    "\n",
    "print(f\"\\nJacobian sparsity: {J_pattern.nnz / (J_pattern.shape[0]**2) * 100:.1f}%\")\n",
    "\n",
    "# Visualize Jacobian structure\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.spy(J_pattern, markersize=5)\n",
    "plt.title('Jacobian Sparsity Pattern')\n",
    "plt.xlabel('Column Index')\n",
    "plt.ylabel('Row Index')\n",
    "\n",
    "# Add grid to show sub-matrices\n",
    "n_pv = np.sum(bus_types == 1)\n",
    "n_pq = np.sum(bus_types == 2)\n",
    "plt.axhline(y=n_pv + n_pq - 0.5, color='r', linewidth=2)\n",
    "plt.axvline(x=n_pv + n_pq - 0.5, color='r', linewidth=2)\n",
    "plt.text(2, 2, 'J11', fontsize=12, color='blue')\n",
    "plt.text(n_pv + n_pq + 1, 2, 'J12', fontsize=12, color='blue')\n",
    "plt.text(2, n_pv + n_pq + 1, 'J21', fontsize=12, color='blue')\n",
    "plt.text(n_pv + n_pq + 1, n_pv + n_pq + 1, 'J22', fontsize=12, color='blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing for Numerical Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key numerical concepts for Module 04\n",
    "\n",
    "# 1. Matrix reordering for sparsity preservation\n",
    "from scipy.sparse import csgraph\n",
    "\n",
    "# Create a sample sparse matrix\n",
    "n = 20\n",
    "A = sp.random(n, n, density=0.2, format='csr')\n",
    "A = A + A.T + sp.eye(n) * 5\n",
    "\n",
    "# Find reordering to minimize fill-in\n",
    "perm = csgraph.reverse_cuthill_mckee(A)\n",
    "A_reordered = A[perm][:, perm]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax1.spy(A, markersize=3)\n",
    "ax1.set_title('Original Matrix')\n",
    "\n",
    "ax2.spy(A_reordered, markersize=3)\n",
    "ax2.set_title('Reordered Matrix (RCM)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Convergence monitoring for iterative methods\n",
    "def power_iteration_with_monitoring(A, max_iter=100, tol=1e-6):\n",
    "    \"\"\"Power iteration to find dominant eigenvalue\"\"\"\n",
    "    n = A.shape[0]\n",
    "    x = np.random.randn(n)\n",
    "    x = x / np.linalg.norm(x)\n",
    "    \n",
    "    convergence_history = []\n",
    "    eigenvalue_history = []\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        x_new = A @ x\n",
    "        eigenvalue = np.dot(x, x_new)\n",
    "        x_new = x_new / np.linalg.norm(x_new)\n",
    "        \n",
    "        # Convergence metric\n",
    "        convergence = np.linalg.norm(x_new - x)\n",
    "        convergence_history.append(convergence)\n",
    "        eigenvalue_history.append(eigenvalue)\n",
    "        \n",
    "        if convergence < tol:\n",
    "            break\n",
    "            \n",
    "        x = x_new\n",
    "    \n",
    "    return eigenvalue, x, convergence_history, eigenvalue_history\n",
    "\n",
    "# Test on a small matrix\n",
    "A_test = np.array([[4, 1, 1], [1, 3, 0], [1, 0, 2]])\n",
    "eigval, eigvec, conv_hist, eigval_hist = power_iteration_with_monitoring(A_test)\n",
    "\n",
    "# True eigenvalue for comparison\n",
    "true_eigvals = np.linalg.eigvals(A_test)\n",
    "true_dominant = np.max(np.abs(true_eigvals))\n",
    "\n",
    "print(\"Power Iteration Results:\")\n",
    "print(f\"Computed eigenvalue: {eigval:.6f}\")\n",
    "print(f\"True dominant eigenvalue: {true_dominant:.6f}\")\n",
    "print(f\"Error: {abs(eigval - true_dominant):.2e}\")\n",
    "print(f\"Iterations: {len(conv_hist)}\")\n",
    "\n",
    "# Plot convergence\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.semilogy(conv_hist)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Convergence Metric')\n",
    "plt.title('Convergence History')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(eigval_hist)\n",
    "plt.axhline(y=true_dominant, color='r', linestyle='--', label='True value')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Eigenvalue Estimate')\n",
    "plt.title('Eigenvalue Convergence')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 5: Comprehensive Sparse System\n",
    ":class: dropdown\n",
    "\n",
    "Create a complete sparse matrix workflow:\n",
    "1. Build a 200-bus radial + mesh network (main feeder + cross connections)\n",
    "2. Construct the Y-bus matrix using sparse format\n",
    "3. Perform LU factorization and analyze fill-in\n",
    "4. Solve power flow equations with multiple load scenarios\n",
    "5. Compare direct vs iterative solver performance\n",
    "6. Implement simple contingency analysis (remove lines)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Solution to Exercise 5\n",
    "# Build network\n",
    "n_buses = 200\n",
    "branches = []\n",
    "\n",
    "# Main radial feeder\n",
    "for i in range(n_buses - 1):\n",
    "    z = (0.01 + 0.03j) * np.random.uniform(0.8, 1.2)\n",
    "    branches.append((i, i+1, 1/z))\n",
    "\n",
    "# Add mesh connections (every 20 buses)\n",
    "for i in range(0, n_buses-20, 20):\n",
    "    for j in range(i+5, min(i+20, n_buses), 5):\n",
    "        if np.random.rand() > 0.5:  # 50% chance\n",
    "            z = (0.02 + 0.06j) * np.random.uniform(0.8, 1.2)\n",
    "            branches.append((i, j, 1/z))\n",
    "\n",
    "print(f\"Network Configuration:\")\n",
    "print(f\"Buses: {n_buses}\")\n",
    "print(f\"Branches: {len(branches)}\")\n",
    "\n",
    "# Build Y-bus\n",
    "Y_bus = sp.lil_matrix((n_buses, n_buses), dtype=complex)\n",
    "for i, j, y in branches:\n",
    "    Y_bus[i, j] -= y\n",
    "    Y_bus[j, i] -= y\n",
    "    Y_bus[i, i] += y\n",
    "    Y_bus[j, j] += y\n",
    "\n",
    "Y_bus = Y_bus.tocsr()\n",
    "print(f\"Y-bus: {Y_bus.nnz} non-zeros ({Y_bus.nnz/(n_buses**2)*100:.2f}% dense)\")\n",
    "\n",
    "# LU factorization analysis\n",
    "lu = sp_linalg.splu(Y_bus.tocsc())\n",
    "fill_in = (lu.L.nnz + lu.U.nnz - Y_bus.nnz) / Y_bus.nnz * 100\n",
    "print(f\"\\nLU Factorization:\")\n",
    "print(f\"Fill-in: {fill_in:.1f}%\")\n",
    "\n",
    "# Multiple load scenarios\n",
    "n_scenarios = 10\n",
    "load_scenarios = np.random.uniform(0.5, 1.5, (n_buses, n_scenarios))\n",
    "load_scenarios[0, :] = 0  # Slack bus\n",
    "\n",
    "# Solve with direct method\n",
    "print(f\"\\nSolving {n_scenarios} load scenarios:\")\n",
    "start = time.time()\n",
    "V_direct = np.zeros((n_buses, n_scenarios), dtype=complex)\n",
    "for i in range(n_scenarios):\n",
    "    I = load_scenarios[:, i] * np.exp(1j * np.random.uniform(-0.5, 0.5, n_buses))\n",
    "    V_direct[:, i] = lu.solve(I)\n",
    "time_direct = time.time() - start\n",
    "\n",
    "# Solve with iterative method\n",
    "start = time.time()\n",
    "V_iterative = np.zeros((n_buses, n_scenarios), dtype=complex)\n",
    "for i in range(n_scenarios):\n",
    "    I = load_scenarios[:, i] * np.exp(1j * np.random.uniform(-0.5, 0.5, n_buses))\n",
    "    V_iterative[:, i], _ = sp_linalg.gmres(Y_bus, I, tol=1e-8)\n",
    "time_iterative = time.time() - start\n",
    "\n",
    "print(f\"Direct (LU): {time_direct*1000:.1f} ms\")\n",
    "print(f\"Iterative (GMRES): {time_iterative*1000:.1f} ms\")\n",
    "print(f\"Direct faster by: {time_iterative/time_direct:.1f}x\")\n",
    "\n",
    "# Verify accuracy\n",
    "max_diff = np.max(np.abs(V_direct - V_iterative))\n",
    "print(f\"\\nMax difference: {max_diff:.2e}\")\n",
    "\n",
    "# Contingency analysis\n",
    "print(f\"\\nContingency Analysis:\")\n",
    "# Remove a critical line\n",
    "critical_line = len(branches) // 2\n",
    "i_remove, j_remove, y_remove = branches[critical_line]\n",
    "\n",
    "# Create contingency Y-bus\n",
    "Y_contingency = Y_bus.tolil()\n",
    "Y_contingency[i_remove, j_remove] += y_remove\n",
    "Y_contingency[j_remove, i_remove] += y_remove\n",
    "Y_contingency[i_remove, i_remove] -= y_remove\n",
    "Y_contingency[j_remove, j_remove] -= y_remove\n",
    "Y_contingency = Y_contingency.tocsr()\n",
    "\n",
    "# Check if system is still connected\n",
    "n_components, labels = csgraph.connected_components(Y_contingency, directed=False)\n",
    "print(f\"Line {i_remove}-{j_remove} removed\")\n",
    "print(f\"Connected components: {n_components}\")\n",
    "\n",
    "if n_components == 1:\n",
    "    # Solve contingency case\n",
    "    I_test = load_scenarios[:, 0] * np.exp(1j * np.random.uniform(-0.5, 0.5, n_buses))\n",
    "    V_normal = sp_linalg.spsolve(Y_bus, I_test)\n",
    "    V_contingency = sp_linalg.spsolve(Y_contingency, I_test)\n",
    "    \n",
    "    # Voltage deviation\n",
    "    V_deviation = np.abs(V_contingency) - np.abs(V_normal)\n",
    "    worst_bus = np.argmin(V_deviation)\n",
    "    \n",
    "    print(f\"\\nVoltage impact:\")\n",
    "    print(f\"Worst affected bus: {worst_bus}\")\n",
    "    print(f\"Voltage drop: {V_deviation[worst_bus]:.3f} p.u.\")\n",
    "    print(f\"Average voltage drop: {np.mean(V_deviation):.3f} p.u.\")\n",
    "else:\n",
    "    print(\"System islanded - contingency creates disconnected network\")\n",
    "\n",
    "# Performance summary\n",
    "print(f\"\\nPerformance Summary:\")\n",
    "print(f\"Sparse matrix operations enable analysis of {n_buses}-bus system\")\n",
    "print(f\"Memory savings: ~{(1 - Y_bus.nnz/(n_buses**2))*100:.0f}%\")\n",
    "print(f\"LU factorization enables fast multi-scenario analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This advanced NumPy lesson has prepared you for the numerical methods in Module 04 by covering:\n",
    "\n",
    "**Sparse Matrices**: We learned how to create, manipulate, and efficiently operate on sparse matrices that are ubiquitous in power system analysis. The memory and computational savings are essential for realistic system sizes.\n",
    "\n",
    "**Advanced Linear Algebra**: LU factorization, iterative solvers, and eigenvalue analysis form the mathematical foundation for power flow, stability analysis, and optimization in Module 04.\n",
    "\n",
    "**Performance Optimization**: Understanding memory layout, vectorization, and NumPy's optimized functions enables you to write efficient code for large-scale power system problems.\n",
    "\n",
    "**Numerical Stability**: Concepts like matrix conditioning and iterative refinement are crucial for robust power system software that handles ill-conditioned problems.\n",
    "\n",
    "These advanced techniques bridge the gap between basic array operations and the sophisticated numerical methods you'll implement in Module 04. The skills learned here will enable you to tackle real-world power system problems efficiently.\n",
    "\n",
    "```{admonition} Preparation for Module 04\n",
    ":class: tip\n",
    "\n",
    "Before starting Module 04, ensure you're comfortable with:\n",
    "1. Creating and manipulating sparse matrices in different formats\n",
    "2. Solving large linear systems using both direct and iterative methods\n",
    "3. Understanding the performance implications of different approaches\n",
    "4. Building Jacobian matrices and understanding their structure\n",
    "5. Implementing iterative algorithms with convergence monitoring\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Time Series Analysis\n",
    "\n",
    "| Information | Details |\n",
    "|----------|---------|\n",
    "| Learning Objectives | • Work with datetime data in pandas<br>• Apply time series operations to power system data<br>• Identify daily and weekly load patterns<br>• Implement basic forecasting methods<br>• Decompose time series into components |\n",
    "| Prerequisites | Python fundamentals, NumPy basics, Pandas data manipulation |\n",
    "| Estimated Time | 2 hours |\n",
    "| Topics | Datetime indexing, resampling, rolling windows, pattern analysis, simple forecasting, decomposition |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Time series analysis is fundamental to power system operations. System operators analyze historical load patterns to forecast future demand, schedule generation resources, and ensure grid stability. This lesson teaches practical time series techniques specifically for power system data.\n",
    "\n",
    "Power systems exhibit strong temporal patterns driven by human behavior and weather conditions. Morning load increases as people wake up and businesses open. Evening peaks occur when residential cooling and lighting demands coincide. Weekends show different patterns than weekdays. Understanding and forecasting these patterns is crucial for reliable and economic grid operation.\n",
    "\n",
    "We'll start with pandas datetime functionality, then progress through pattern identification to basic forecasting. All examples use realistic power system data scales and patterns you'll encounter in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_rows', 10)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(42)  # For reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Working with Datetime Data\n",
    "\n",
    "Power system data is inherently temporal. Measurements are recorded at specific times, and the timestamp is as important as the value itself. Pandas provides powerful tools for working with datetime data through its DatetimeIndex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Creating Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a week of hourly timestamps\n",
    "dates = pd.date_range(start='2024-01-01', \n",
    "                     end='2024-01-07 23:00:00', \n",
    "                     freq='h')\n",
    "print(f\"Created {len(dates)} hourly timestamps\")\n",
    "print(f\"First: {dates[0]}\")\n",
    "print(f\"Last: {dates[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate simple load data with daily pattern\n",
    "hours = np.arange(len(dates))\n",
    "daily_pattern = 100 * np.sin((hours % 24) * 2 * np.pi / 24 - np.pi/2) + 500\n",
    "noise = np.random.normal(0, 10, len(dates))\n",
    "load = daily_pattern + noise\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'load': load\n",
    "}, index=dates)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Datetime Components\n",
    "\n",
    "The DatetimeIndex provides easy access to datetime components, which is essential for analyzing patterns and creating features for forecasting models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract datetime components\n",
    "df['hour'] = df.index.hour\n",
    "df['day_of_week'] = df.index.day_name()\n",
    "df['date'] = df.index.date\n",
    "\n",
    "# Show a few rows\n",
    "df[['load', 'hour', 'day_of_week']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Tip: Datetime Indexing\n",
    ":class: tip\n",
    "With a DatetimeIndex, you can slice data using string dates: `df['2024-01-03']` gets all data for January 3rd, and `df['2024-01-03':'2024-01-04']` gets a range.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select specific time periods\n",
    "jan_3 = df.loc['2024-01-03']\n",
    "print(f\"January 3rd has {len(jan_3)} hours of data\")\n",
    "print(f\"Peak load: {jan_3['load'].max():.1f} MW at hour {jan_3['load'].idxmax().hour}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Basic Time Series Operations\n",
    "\n",
    "Power system analysis frequently requires aggregating high-frequency data and calculating moving statistics. These operations help identify trends and smooth out noise in measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Resampling: Changing Time Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resample hourly to daily\n",
    "daily = df['load'].resample('D').agg({\n",
    "    'mean': 'mean',\n",
    "    'max': 'max',\n",
    "    'min': 'min'\n",
    "})\n",
    "\n",
    "daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "```{admonition} Important: Resampling Rules\n",
    ":class: important\n",
    "Common frequency codes: 'h' (hourly), 'D' (daily), 'W' (weekly), 'M' (monthly). Always specify an aggregation method (mean, sum, max, etc.) when downsampling.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Rolling Windows and Moving Averages\n",
    "\n",
    "Moving averages smooth out short-term fluctuations and highlight longer-term trends. They're fundamental to many forecasting methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate rolling statistics\n",
    "df['ma_6h'] = df['load'].rolling(window=6, center=True).mean()\n",
    "df['ma_24h'] = df['load'].rolling(window=24, center=True).mean()\n",
    "\n",
    "# Plot original vs smoothed\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(df.index, df['load'], alpha=0.5, label='Hourly')\n",
    "plt.plot(df.index, df['ma_6h'], label='6-hour MA')\n",
    "plt.plot(df.index, df['ma_24h'], label='24-hour MA')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Load (MW)')\n",
    "plt.title('Load with Moving Averages')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Calculating Changes and Growth Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate hour-to-hour changes\n",
    "df['change'] = df['load'].diff()\n",
    "df['pct_change'] = df['load'].pct_change() * 100\n",
    "\n",
    "# Find largest changes\n",
    "max_increase = df['change'].max()\n",
    "max_decrease = df['change'].min()\n",
    "print(f\"Max hourly increase: {max_increase:.1f} MW\")\n",
    "print(f\"Max hourly decrease: {max_decrease:.1f} MW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Identifying Load Patterns\n",
    "\n",
    "Power system loads follow predictable patterns. Daily patterns reflect human activity cycles, while weekly patterns show the difference between weekdays and weekends. Identifying these patterns is the first step toward accurate forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Daily Load Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate average hourly profile\n",
    "hourly_profile = df.groupby('hour')['load'].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(hourly_profile.index, hourly_profile.values, marker='o')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Average Load (MW)')\n",
    "plt.title('Average Daily Load Profile')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(range(0, 24, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "```{admonition} Tip: Peak Hours\n",
    ":class: tip\n",
    "Most power systems see morning peaks (6-9 AM) and evening peaks (5-8 PM). The evening peak is typically higher due to combined residential and commercial loads.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify peak hours\n",
    "peak_hour = hourly_profile.idxmax()\n",
    "min_hour = hourly_profile.idxmin()\n",
    "print(f\"Peak typically at hour {peak_hour} ({peak_hour}:00)\")\n",
    "print(f\"Minimum typically at hour {min_hour} ({min_hour}:00)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Weekly Patterns\n",
    "\n",
    "Weekday and weekend loads differ significantly. Industrial and commercial loads drop on weekends, while residential patterns change due to different wake and activity times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create more data for weekly analysis\n",
    "dates_month = pd.date_range(start='2024-01-01', periods=30*24, freq='h')\n",
    "hours_month = np.arange(len(dates_month))\n",
    "\n",
    "# Add weekly pattern (lower on weekends)\n",
    "daily_base = 100 * np.sin((hours_month % 24) * 2 * np.pi / 24 - np.pi/2) + 500\n",
    "weekend_factor = np.where(dates_month.weekday >= 5, 0.8, 1.0)\n",
    "load_month = daily_base * weekend_factor + np.random.normal(0, 10, len(dates_month))\n",
    "\n",
    "df_month = pd.DataFrame({'load': load_month}, index=dates_month)\n",
    "df_month['is_weekend'] = df_month.index.weekday >= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compare weekday vs weekend\n",
    "weekday_avg = df_month[~df_month['is_weekend']]['load'].mean()\n",
    "weekend_avg = df_month[df_month['is_weekend']]['load'].mean()\n",
    "\n",
    "print(f\"Average weekday load: {weekday_avg:.1f} MW\")\n",
    "print(f\"Average weekend load: {weekend_avg:.1f} MW\")\n",
    "print(f\"Weekend reduction: {(1 - weekend_avg/weekday_avg)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Simple Forecasting Methods\n",
    "\n",
    "Before applying complex models, it's important to establish baseline forecasts using simple methods. These baselines help evaluate whether more sophisticated approaches actually improve accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Naive Forecast: Using Yesterday's Value\n",
    "\n",
    "The simplest forecast assumes tomorrow will be like today. For power systems, we typically use \"yesterday same hour\" as the naive forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create train and test sets\n",
    "train = df_month['2024-01-01':'2024-01-21']\n",
    "test = df_month['2024-01-22':'2024-01-24']\n",
    "\n",
    "# Naive forecast: use same hour from previous day\n",
    "naive_forecast = train['load'].shift(24).iloc[-len(test):]\n",
    "naive_forecast.index = test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate error metrics\n",
    "mae = np.mean(np.abs(test['load'] - naive_forecast))\n",
    "mape = np.mean(np.abs((test['load'] - naive_forecast) / test['load'])) * 100\n",
    "\n",
    "print(f\"Naive Forecast Performance:\")\n",
    "print(f\"MAE: {mae:.2f} MW\")\n",
    "print(f\"MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "```{admonition} Important: Forecast Metrics\n",
    ":class: important\n",
    "MAE (Mean Absolute Error) measures average error in MW. MAPE (Mean Absolute Percentage Error) measures relative error. MAPE is useful for comparing accuracy across different load levels.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Moving Average Forecast\n",
    "\n",
    "Moving averages smooth out random fluctuations and can provide better forecasts than naive methods when there's high volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create moving average forecast\n",
    "window = 24  # Use last 24 hours\n",
    "ma_forecast = train['load'].rolling(window=window).mean().iloc[-1]\n",
    "\n",
    "# For simplicity, use constant forecast\n",
    "ma_forecast_series = pd.Series([ma_forecast] * len(test), index=test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Similar Day Forecast\n",
    "\n",
    "Power systems show strong weekly patterns. Using the same day from the previous week often provides good forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Similar day: same hour from same day last week\n",
    "similar_day_forecast = train['load'].shift(7*24).iloc[-len(test):]\n",
    "similar_day_forecast.index = test.index\n",
    "\n",
    "# Calculate performance\n",
    "mae_similar = np.mean(np.abs(test['load'] - similar_day_forecast))\n",
    "print(f\"Similar Day MAE: {mae_similar:.2f} MW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Comparing Forecast Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot first 48 hours of test period\n",
    "plot_hours = 48\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(test.index[:plot_hours], test['load'][:plot_hours], \n",
    "         'k-', label='Actual', linewidth=2)\n",
    "plt.plot(test.index[:plot_hours], naive_forecast[:plot_hours], \n",
    "         'b--', label='Naive', alpha=0.7)\n",
    "plt.plot(test.index[:plot_hours], similar_day_forecast[:plot_hours], \n",
    "         'r--', label='Similar Day', alpha=0.7)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Load (MW)')\n",
    "plt.title('Forecast Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Time Series Decomposition\n",
    "\n",
    "Decomposition separates a time series into trend, seasonal, and residual components. This helps understand the underlying structure and can improve forecasting by modeling each component separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Decompose one week of data\n",
    "week_data = df['2024-01-01':'2024-01-07']['load']\n",
    "decomposition = seasonal_decompose(week_data, model='additive', period=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot components\n",
    "fig, axes = plt.subplots(4, 1, figsize=(12, 8))\n",
    "\n",
    "week_data.plot(ax=axes[0], title='Original')\n",
    "axes[0].set_ylabel('Load (MW)')\n",
    "\n",
    "decomposition.trend.plot(ax=axes[1], title='Trend')\n",
    "axes[1].set_ylabel('Trend')\n",
    "\n",
    "decomposition.seasonal.plot(ax=axes[2], title='Seasonal (24-hour)')\n",
    "axes[2].set_ylabel('Seasonal')\n",
    "\n",
    "decomposition.resid.plot(ax=axes[3], title='Residual')\n",
    "axes[3].set_ylabel('Residual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "```{admonition} Warning: Decomposition Assumptions\n",
    ":class: warning\n",
    "Additive decomposition assumes seasonal fluctuations are constant over time. Use multiplicative decomposition if seasonal patterns scale with the level of the time series.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercise 1: Daily Peak Detection\n",
    "\n",
    "Power system operators need to know when daily peaks occur to schedule generation resources. In this exercise, you'll analyze a week of load data to find the daily peak loads and their timing.\n",
    "\n",
    "Using the provided week of hourly load data, find the peak load and peak hour for each day. Calculate the average peak load across the week and identify which day had the highest peak. Also determine what hour of the day most commonly experiences the peak load.\n",
    "\n",
    "```{admonition} Hint\n",
    ":class: hint\n",
    "Use `groupby` with the date to analyze each day separately. The `idxmax()` method returns the index (timestamp) of the maximum value, from which you can extract the hour.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "# Data for the exercise\n",
    "exercise_data = df['2024-01-01':'2024-01-07']['load']\n",
    "\n",
    "# Find daily peaks and their timing\n",
    "# Your solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "# Group by date and find max\n",
    "daily_peaks = exercise_data.groupby(exercise_data.index.date).agg(['max', 'idxmax'])\n",
    "\n",
    "# Extract peak hours\n",
    "daily_peaks['peak_hour'] = daily_peaks['idxmax'].dt.hour\n",
    "\n",
    "# Display results\n",
    "print(\"Daily Peak Analysis:\")\n",
    "print(daily_peaks[['max', 'peak_hour']])\n",
    "print(f\"\\nAverage peak load: {daily_peaks['max'].mean():.1f} MW\")\n",
    "print(f\"Highest peak: {daily_peaks['max'].max():.1f} MW on {daily_peaks['max'].idxmax()}\")\n",
    "print(f\"Most common peak hour: {daily_peaks['peak_hour'].mode()[0]}:00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercise 2: Simple Load Forecast\n",
    "\n",
    "Accurate load forecasting is essential for power system operations. In this exercise, you'll implement and evaluate a simple 24-hour ahead forecast using a moving average approach.\n",
    "\n",
    "Create a forecast for January 8th using the previous 7 days of data (January 1-7). Use a 24-hour moving average of the same hours from previous days. For example, to forecast 10 AM on January 8th, average the 10 AM values from January 1-7. Calculate the MAE and MAPE for your forecast. Compare your results to a naive forecast that simply uses January 7th's values.\n",
    "\n",
    "```{admonition} Hint\n",
    ":class: hint\n",
    "Group the historical data by hour of day, then calculate the mean for each hour. This gives you an average profile that can be used as your forecast for the next day.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exercise 2: Your code here\n",
    "# Historical data (7 days)\n",
    "historical = df['2024-01-01':'2024-01-07']['load']\n",
    "\n",
    "# Actual data for January 8th (to evaluate forecast)\n",
    "dates_jan8 = pd.date_range(start='2024-01-08', periods=24, freq='h')\n",
    "# Generate actual values for testing\n",
    "np.random.seed(42)\n",
    "hours_jan8 = np.arange(24) + 7*24  # Hours since start\n",
    "actual_jan8 = 100 * np.sin((hours_jan8 % 24) * 2 * np.pi / 24 - np.pi/2) + 500\n",
    "actual_jan8 += np.random.normal(0, 10, 24)\n",
    "actual = pd.Series(actual_jan8, index=dates_jan8)\n",
    "\n",
    "# Create your forecast here:\n",
    "# Your solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "# Method 1: Average by hour\n",
    "hourly_avg = historical.groupby(historical.index.hour).mean()\n",
    "forecast = pd.Series(hourly_avg.values, index=actual.index)\n",
    "\n",
    "# Method 2: Naive (use January 7th)\n",
    "jan7_data = df.loc['2024-01-07']['load']\n",
    "naive = pd.Series(jan7_data.values, index=actual.index)\n",
    "\n",
    "# Calculate errors\n",
    "mae_forecast = np.mean(np.abs(actual - forecast))\n",
    "mape_forecast = np.mean(np.abs((actual - forecast) / actual)) * 100\n",
    "\n",
    "mae_naive = np.mean(np.abs(actual - naive))\n",
    "mape_naive = np.mean(np.abs((actual - naive) / actual)) * 100\n",
    "\n",
    "print(\"Forecast Performance:\")\n",
    "print(f\"Moving Average - MAE: {mae_forecast:.2f} MW, MAPE: {mape_forecast:.2f}%\")\n",
    "print(f\"Naive - MAE: {mae_naive:.2f} MW, MAPE: {mape_naive:.2f}%\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(actual.index, actual.values, 'k-', label='Actual', linewidth=2)\n",
    "plt.plot(forecast.index, forecast.values, 'b--', label='Moving Avg', alpha=0.7)\n",
    "plt.plot(naive.index, naive.values, 'r--', label='Naive', alpha=0.7)\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Load (MW)')\n",
    "plt.title('24-Hour Ahead Forecast Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Summary\n",
    "\n",
    "This lesson covered essential time series techniques for power system analysis. You learned to work with datetime data in pandas, identify load patterns, and implement basic forecasting methods. Time series decomposition revealed how loads combine trend, seasonal, and random components.\n",
    "\n",
    "The simple forecasting methods we explored often perform surprisingly well for stable power systems. Moving averages smooth volatility, while similar-day approaches leverage weekly patterns. These techniques form the foundation for more advanced methods like ARIMA and machine learning models.\n",
    "\n",
    "Power system operators use these techniques daily to forecast loads, schedule generation, and ensure reliable electricity supply. As renewable energy increases, accurate forecasting becomes even more critical for managing variable generation and maintaining grid stability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
